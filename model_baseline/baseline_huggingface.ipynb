{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:38:42.486877100Z",
     "start_time": "2024-02-04T10:38:42.474284900Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:06.705217800Z",
     "start_time": "2024-02-04T10:38:42.483655900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x1a5c8779c90>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import logging, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "logging.set_verbosity_error()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:10.190806300Z",
     "start_time": "2024-02-04T10:39:06.701688Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/full_train_data_summarization.csv')\n",
    "validation_data = pd.read_csv('../dataset/full_validation_data_summarization.csv')\n",
    "test_data = pd.read_csv('../dataset/full_test_data_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:10.205827100Z",
     "start_time": "2024-02-04T10:39:10.190806300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = train_data[:6000]\n",
    "validation_data = validation_data[:300]\n",
    "test_data = test_data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:10.229473200Z",
     "start_time": "2024-02-04T10:39:10.207968Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'google/mt5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:22.690308600Z",
     "start_time": "2024-02-04T10:39:13.663736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/82.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4d7d53d8d6b45808562fd8e6839949e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/553 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "60392dfac13d470cb343bd7ec3bf431e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bc4930806024afba48154dc2574f794"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5590a6cc36fa466484f98437fc351860"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:24.900285200Z",
     "start_time": "2024-02-04T10:39:24.878907600Z"
    }
   },
   "outputs": [],
   "source": [
    "prefix = \"Hãy tóm tắt ngắn gọn nội dung sau bằng tiếng Việt: \"\n",
    "def preprocess_function(examples):\n",
    "  inputs = [prefix + doc for doc in examples[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=4096, truncation=True)\n",
    "  labels = tokenizer(text_target=examples[\"summarization\"], max_length=1024, truncation=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:27.084875200Z",
     "start_time": "2024-02-04T10:39:26.837162800Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(validation_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:36.910769Z",
     "start_time": "2024-02-04T10:39:29.635534900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b5515e2addc4fb690d4de6f8970b39f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/300 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "350069060e554bb293a7d5bf1e121082"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_new_data = new_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:43.023531600Z",
     "start_time": "2024-02-04T10:39:43.006130900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:40:18.257759300Z",
     "start_time": "2024-02-04T10:40:18.235574300Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  bleu_scores_ngram_1 = []\n",
    "  bleu_scores_ngram_2 = []\n",
    "  bleu_scores_ngram_3 = []\n",
    "  bleu_scores_ngram_4 = []\n",
    "  bleu_scores_ngram_avg = []\n",
    "  for reference_text, generated_text in zip(decoded_labels, decoded_preds):\n",
    "    bleu_score_ngram_1 = sentence_bleu([reference_text], generated_text, weights=(1, 0, 0, 0))\n",
    "    bleu_score_ngram_2 = sentence_bleu([reference_text], generated_text, weights=(0, 1, 0, 0))\n",
    "    bleu_score_ngram_3 = sentence_bleu([reference_text], generated_text, weights=(0, 0, 1, 0))\n",
    "    bleu_score_ngram_4 = sentence_bleu([reference_text], generated_text, weights=(0, 0, 0, 1))\n",
    "    bleu_score_ngram_avg = sentence_bleu([reference_text], generated_text, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_scores_ngram_1.append(bleu_score_ngram_1)\n",
    "    bleu_scores_ngram_2.append(bleu_score_ngram_2)\n",
    "    bleu_scores_ngram_3.append(bleu_score_ngram_3)\n",
    "    bleu_scores_ngram_4.append(bleu_score_ngram_4)\n",
    "    bleu_scores_ngram_avg.append(bleu_score_ngram_avg)\n",
    "\n",
    "  return {\n",
    "    'bleu@1': sum(bleu_scores_ngram_1) / len(bleu_scores_ngram_1),\n",
    "    'bleu@2': sum(bleu_scores_ngram_2) / len(bleu_scores_ngram_2),\n",
    "    'bleu@3': sum(bleu_scores_ngram_3) / len(bleu_scores_ngram_3),\n",
    "    'bleu@4': sum(bleu_scores_ngram_4) / len(bleu_scores_ngram_4),\n",
    "    'bleu@avg': sum(bleu_scores_ngram_avg) / len(bleu_scores_ngram_avg)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:03.341757Z",
     "start_time": "2024-02-04T10:40:19.761684700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "894350251f4949349bd92ee1fffe9889"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "308a2aa0327348be86c3a3d285c8bc18"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:03.374728300Z",
     "start_time": "2024-02-04T10:41:03.343520200Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name.replace('/', '_').replace('-', '_')}_model_summarization\",\n",
    "    learning_rate=1e-5,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    bf16=True,\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=1,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:04.950004800Z",
     "start_time": "2024-02-04T10:41:03.375831900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "157"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_new_data[\"train\"],\n",
    "    eval_dataset=tokenized_new_data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ''\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model.to(device)\n",
    "if torch.cuda.device_count() >= 2:\n",
    "  model = torch.nn.DataParallel(model)\n",
    "\n",
    "def generate_text(text):\n",
    "  prefix = 'Hãy tóm tắt ngắn gọn nội dung sau bằng tiếng Việt: '\n",
    "  encoding = tokenizer(prefix+text, return_tensors=\"pt\")\n",
    "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "  outputs = model.module.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    early_stopping=False,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    "    repetition_penalty=1.2\n",
    "  )\n",
    "  for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[f'generate_{model_name.replace(\"/\", \"_\").replace(\"-\", \"_\")}'] = test_data['context'].apply(lambda x: generate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
