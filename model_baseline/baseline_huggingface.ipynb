{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:02:58.953735100Z",
     "start_time": "2024-02-06T11:02:58.942583600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:02:59.388697Z",
     "start_time": "2024-02-06T11:02:59.194825300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc3a092f910>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import logging, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType, PeftConfig, PeftModel\n",
    "tqdm.pandas()\n",
    "logging.set_verbosity_error()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:03:05.920834Z",
     "start_time": "2024-02-06T11:03:03.208345300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/full_train_data_summarization.csv')\n",
    "validation_data = pd.read_csv('../dataset/full_validation_data_summarization.csv')\n",
    "test_data = pd.read_csv('../dataset/full_test_data_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:10.229473200Z",
     "start_time": "2024-02-04T10:39:10.207968Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'VietAI/vit5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:22.690308600Z",
     "start_time": "2024-02-04T10:39:13.663736Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:24.900285200Z",
     "start_time": "2024-02-04T10:39:24.878907600Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "  inputs = [doc for doc in examples[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=2048, truncation=True, padding=True)\n",
    "  labels = tokenizer(text_target=examples[\"summarization\"], max_length=1024, truncation=True, padding=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:27.084875200Z",
     "start_time": "2024-02-04T10:39:26.837162800Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(validation_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91155c06563647028050681ec816ba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50413 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1960facdf3c34edfbfac8f67966dfade",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/2200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Map dataset with multiprocessing\n",
    "tokenized_new_data = new_data.map(preprocess_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map dataset not with multiprocessing\n",
    "tokenized_new_data = new_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:40:18.257759300Z",
     "start_time": "2024-02-04T10:40:18.235574300Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels.tolist(), skip_special_tokens=True)\n",
    "  decoded_preds = tokenizer.batch_decode(preds.tolist(), skip_special_tokens=True)\n",
    "  bleu_metric = evaluate.load(\"bleu\")\n",
    "  references = [[reference_text] for reference_text in decoded_labels]\n",
    "  bleu_scores = bleu_metric.compute(references=references, predictions=decoded_preds)\n",
    "  bleu_score_1 = None\n",
    "  bleu_score_2 = None\n",
    "  bleu_score_3 = None\n",
    "  bleu_score_4 = None\n",
    "  bleu_score_avg = None\n",
    "  for k, v in bleu_scores.items():\n",
    "    if k == \"precisions\":\n",
    "      bleu_score_1 = v[0]\n",
    "      bleu_score_2 = v[1]        \n",
    "      bleu_score_3 = v[2]        \n",
    "      bleu_score_4 = v[3]\n",
    "      bleu_score_avg = (bleu_score_1 + bleu_score_2 + bleu_score_3 + bleu_score_4)/4\n",
    "      break\n",
    "  return {\n",
    "    'bleu@1': bleu_score_1,\n",
    "    'bleu@2': bleu_score_2,\n",
    "    'bleu@3': bleu_score_3,\n",
    "    'bleu@4': bleu_score_4,\n",
    "    'bleu@avg': bleu_score_avg\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  rouge_metric = evaluate.load(\"rouge\")\n",
    "  rouge_scores = rouge_metric.compute(references=decoded_labels, predictions=decoded_preds, use_stemmer=True, rouge_types=['rouge1', 'rouge2', 'rougeL'])\n",
    "  return {k: round(v, 4) for k, v in rouge_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,538,944 || all params: 229,489,920 || trainable%: 1.5420912604788917\n"
     ]
    }
   ],
   "source": [
    "# Config lora for ViT5 Base Model\n",
    "lora_config = LoraConfig(\n",
    "  r=8, \n",
    "  lora_alpha=16,\n",
    "  target_modules=[\"q\", \"k\", \"v\", \"o\", \"wi\", \"wo\", \"lm_head\"],\n",
    "  lora_dropout=0.05,\n",
    "  bias=\"none\",\n",
    "  task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:43.023531600Z",
     "start_time": "2024-02-04T10:39:43.006130900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:03.374728300Z",
     "start_time": "2024-02-04T10:41:03.343520200Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name.replace('/', '_').replace('-', '_')}_model_summarization\",\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    # auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=12,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    group_by_length=True,\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=2,\n",
    "    report_to='wandb',\n",
    "    run_name=f'{model_name}',\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='no'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:04.950004800Z",
     "start_time": "2024-02-04T10:41:03.375831900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_new_data[\"train\"],\n",
    "    eval_dataset=tokenized_new_data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mphamduchuy159\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/SummarizationVietnamese/model_baseline/wandb/run-20240221_155953-v4zm2gmf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/phamduchuy159/huggingface/runs/v4zm2gmf' target=\"_blank\">VietAI/vit5-base</a></strong> to <a href='https://wandb.ai/phamduchuy159/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/phamduchuy159/huggingface' target=\"_blank\">https://wandb.ai/phamduchuy159/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/phamduchuy159/huggingface/runs/v4zm2gmf' target=\"_blank\">https://wandb.ai/phamduchuy159/huggingface/runs/v4zm2gmf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 25.6401, 'grad_norm': 21.815866470336914, 'learning_rate': 4.757373929590866e-06, 'epoch': 0.12}\n",
      "{'loss': 5.8001, 'grad_norm': 0.7044253349304199, 'learning_rate': 9.514747859181732e-06, 'epoch': 0.24}\n",
      "{'loss': 0.6644, 'grad_norm': 0.42378419637680054, 'learning_rate': 9.775038829600683e-06, 'epoch': 0.36}\n",
      "{'loss': 0.577, 'grad_norm': 0.39273765683174133, 'learning_rate': 9.524525276817477e-06, 'epoch': 0.48}\n",
      "{'loss': 0.5449, 'grad_norm': 0.38890340924263, 'learning_rate': 9.274011724034271e-06, 'epoch': 0.59}\n",
      "{'loss': 0.5303, 'grad_norm': 0.32716238498687744, 'learning_rate': 9.023498171251065e-06, 'epoch': 0.71}\n",
      "{'loss': 0.4934, 'grad_norm': 0.4697178900241852, 'learning_rate': 8.77298461846786e-06, 'epoch': 0.83}\n",
      "{'loss': 0.4766, 'grad_norm': 0.3022129237651825, 'learning_rate': 8.522471065684655e-06, 'epoch': 0.95}\n",
      "{'loss': 0.4754, 'grad_norm': 0.4481845498085022, 'learning_rate': 8.271957512901449e-06, 'epoch': 1.07}\n",
      "{'loss': 0.4752, 'grad_norm': 0.35408300161361694, 'learning_rate': 8.021443960118243e-06, 'epoch': 1.19}\n",
      "{'loss': 0.4588, 'grad_norm': 0.45265114307403564, 'learning_rate': 7.770930407335038e-06, 'epoch': 1.31}\n",
      "{'loss': 0.4537, 'grad_norm': 0.5276682376861572, 'learning_rate': 7.520416854551832e-06, 'epoch': 1.43}\n",
      "{'loss': 0.455, 'grad_norm': 0.4168441593647003, 'learning_rate': 7.269903301768626e-06, 'epoch': 1.55}\n",
      "{'loss': 0.4596, 'grad_norm': 0.3300434648990631, 'learning_rate': 7.01938974898542e-06, 'epoch': 1.67}\n",
      "{'loss': 0.4602, 'grad_norm': 0.50395268201828, 'learning_rate': 6.768876196202216e-06, 'epoch': 1.78}\n",
      "{'loss': 0.4537, 'grad_norm': 0.40451711416244507, 'learning_rate': 6.51836264341901e-06, 'epoch': 1.9}\n",
      "{'loss': 0.4461, 'grad_norm': 0.31650370359420776, 'learning_rate': 6.267849090635804e-06, 'epoch': 2.02}\n",
      "{'loss': 0.4453, 'grad_norm': 0.6509864330291748, 'learning_rate': 6.017335537852599e-06, 'epoch': 2.14}\n",
      "{'loss': 0.4436, 'grad_norm': 0.32116082310676575, 'learning_rate': 5.766821985069393e-06, 'epoch': 2.26}\n",
      "{'loss': 0.451, 'grad_norm': 0.27817046642303467, 'learning_rate': 5.516308432286187e-06, 'epoch': 2.38}\n",
      "{'loss': 0.4392, 'grad_norm': 0.49039214849472046, 'learning_rate': 5.265794879502981e-06, 'epoch': 2.5}\n",
      "{'loss': 0.4507, 'grad_norm': 0.39217740297317505, 'learning_rate': 5.015281326719777e-06, 'epoch': 2.62}\n",
      "{'loss': 0.4383, 'grad_norm': 0.3104865252971649, 'learning_rate': 4.764767773936571e-06, 'epoch': 2.74}\n",
      "{'loss': 0.4315, 'grad_norm': 0.5292973518371582, 'learning_rate': 4.514254221153365e-06, 'epoch': 2.86}\n",
      "{'loss': 0.4429, 'grad_norm': 0.4698503315448761, 'learning_rate': 4.263740668370159e-06, 'epoch': 2.97}\n",
      "{'loss': 0.4398, 'grad_norm': 0.5047674775123596, 'learning_rate': 4.013227115586953e-06, 'epoch': 3.09}\n",
      "{'loss': 0.4393, 'grad_norm': 0.40587642788887024, 'learning_rate': 3.762713562803748e-06, 'epoch': 3.21}\n",
      "{'loss': 0.438, 'grad_norm': 0.5971794724464417, 'learning_rate': 3.512200010020542e-06, 'epoch': 3.33}\n",
      "{'loss': 0.4477, 'grad_norm': 0.37144410610198975, 'learning_rate': 3.261686457237337e-06, 'epoch': 3.45}\n",
      "{'loss': 0.4311, 'grad_norm': 0.5344048738479614, 'learning_rate': 3.011172904454131e-06, 'epoch': 3.57}\n",
      "{'loss': 0.431, 'grad_norm': 0.5857945680618286, 'learning_rate': 2.7606593516709256e-06, 'epoch': 3.69}\n",
      "{'loss': 0.4394, 'grad_norm': 0.5618873238563538, 'learning_rate': 2.51014579888772e-06, 'epoch': 3.81}\n",
      "{'loss': 0.4401, 'grad_norm': 0.41528335213661194, 'learning_rate': 2.2596322461045143e-06, 'epoch': 3.93}\n",
      "{'loss': 0.4228, 'grad_norm': 0.5914547443389893, 'learning_rate': 2.0091186933213087e-06, 'epoch': 4.05}\n",
      "{'loss': 0.4357, 'grad_norm': 0.4752632677555084, 'learning_rate': 1.7586051405381033e-06, 'epoch': 4.16}\n",
      "{'loss': 0.4264, 'grad_norm': 0.4479409456253052, 'learning_rate': 1.5080915877548977e-06, 'epoch': 4.28}\n",
      "{'loss': 0.4395, 'grad_norm': 0.38702020049095154, 'learning_rate': 1.257578034971692e-06, 'epoch': 4.4}\n",
      "{'loss': 0.4304, 'grad_norm': 0.4768015742301941, 'learning_rate': 1.0070644821884864e-06, 'epoch': 4.52}\n",
      "{'loss': 0.4348, 'grad_norm': 0.7409995794296265, 'learning_rate': 7.565509294052809e-07, 'epoch': 4.64}\n",
      "{'loss': 0.4321, 'grad_norm': 0.6859549283981323, 'learning_rate': 5.060373766220754e-07, 'epoch': 4.76}\n",
      "{'loss': 0.4418, 'grad_norm': 0.43679481744766235, 'learning_rate': 2.555238238388697e-07, 'epoch': 4.88}\n",
      "{'loss': 0.4311, 'grad_norm': 0.4233219027519226, 'learning_rate': 5.010271055664111e-09, 'epoch': 5.0}\n",
      "{'train_runtime': 50685.238, 'train_samples_per_second': 4.973, 'train_steps_per_second': 0.415, 'train_loss': 1.1854584875247525, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=21010, training_loss=1.1854584875247525, metrics={'train_runtime': 50685.238, 'train_samples_per_second': 4.973, 'train_steps_per_second': 0.415, 'train_loss': 1.1854584875247525, 'epoch': 5.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208ff94fb0384e3a820d3641d2864d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5341997146606445, 'eval_rouge1': 0.3635, 'eval_rouge2': 0.1837, 'eval_rougeL': 0.2778, 'eval_runtime': 1379.3407, 'eval_samples_per_second': 1.595, 'eval_steps_per_second': 0.399, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5341997146606445,\n",
       " 'eval_rouge1': 0.3635,\n",
       " 'eval_rouge2': 0.1837,\n",
       " 'eval_rougeL': 0.2778,\n",
       " 'eval_runtime': 1379.3407,\n",
       " 'eval_samples_per_second': 1.595,\n",
       " 'eval_steps_per_second': 0.399,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = '../model_baseline/google_mt5_base_model_summarization/checkpoint-18000'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, load_in_8bit=True, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "  encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "  outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    early_stopping=False,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2\n",
    "  )\n",
    "  for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:00<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data[f'generate_vit5'] = test_data['context'].progress_apply(lambda x: generate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>summarization</th>\n",
       "      <th>generate_google_mt5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Để khắc phục các nhược điểm nói trên, Viện Kho...</td>\n",
       "      <td>Viện Khoa học Fraunhofer Đức đang phát triển l...</td>\n",
       "      <td>Viện Khoa học Fraunhofer, Đức đang phát triển ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Không nên dùng sản phẩm sát trùng mạnh như Bac...</td>\n",
       "      <td>Tránh dùng sản phẩm sát trùng mạnh. Tránh tran...</td>\n",
       "      <td>Tóm tắt ngắn gọn nội dung sau để vệ sinh khuyê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kỳ 1: Đổi giờ học, giờ làm - đúng nhưng chưa đ...</td>\n",
       "      <td>Gần đây, Bộ Giao thông vận tải (GTVT) đã đưa r...</td>\n",
       "      <td>Bộ Giao thông vận tải (GTVT) đã đưa ra giải ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theo San Francisco Globe, chú hắc mã này có ng...</td>\n",
       "      <td>Frederik là một con ngựa Frieasian đến từ Hà L...</td>\n",
       "      <td>Ông Frederik là một người hâm mộ của vị vua tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...</td>\n",
       "      <td>Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...</td>\n",
       "      <td>Thứ trưởng Bộ GTVT Nguyễn Nhật và đại diện các...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Trong giai đoạn 2015 2020, Đảng bộ VCCI đã đề ...</td>\n",
       "      <td>Đại hội Đảng bộ VCCI lần thứ VI nhiệm kỳ 2010-...</td>\n",
       "      <td>Tại giai đoạn 2015-2020, Đảng bộ VCCI đã đề ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Bản hit của nhạc sĩ Phạm Toàn Thắng đã có tổng...</td>\n",
       "      <td>Nhạc sĩ Phạm Toàn Thắng đã có bản hit có tổng ...</td>\n",
       "      <td>Tổng hơn 13 triệu lượt view trong năm qua, tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Các lực lượng chức năng đang tiến hành điều tr...</td>\n",
       "      <td>Lực lượng chức năng đang tiến hành điều tra vụ...</td>\n",
       "      <td>Tại hầm đường bộ Phước Tượng, xe ô-tô tải Air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Kodaikanal, Tamil Nadu.\\nMột điểm đến thân thi...</td>\n",
       "      <td>Tại Nam Ấn Độ, có nhiều điểm đến thân thiện gi...</td>\n",
       "      <td>Tìm về Kodaikanal ở Tamil Nadu. Nằm giữa những...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Cây đa Đá Bạc.\\nSáng 23/4, UBND huyện Phú Lộc ...</td>\n",
       "      <td>UBND huyện Phú Lộc đã tổ chức Lễ đón nhận bằng...</td>\n",
       "      <td>Cây đa Đá Bạc, tại thị trấn Phú Lộc là cây di ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Để khắc phục các nhược điểm nói trên, Viện Kho...   \n",
       "1    Không nên dùng sản phẩm sát trùng mạnh như Bac...   \n",
       "2    Kỳ 1: Đổi giờ học, giờ làm - đúng nhưng chưa đ...   \n",
       "3    Theo San Francisco Globe, chú hắc mã này có ng...   \n",
       "4    Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...   \n",
       "..                                                 ...   \n",
       "195  Trong giai đoạn 2015 2020, Đảng bộ VCCI đã đề ...   \n",
       "196  Bản hit của nhạc sĩ Phạm Toàn Thắng đã có tổng...   \n",
       "197  Các lực lượng chức năng đang tiến hành điều tr...   \n",
       "198  Kodaikanal, Tamil Nadu.\\nMột điểm đến thân thi...   \n",
       "199  Cây đa Đá Bạc.\\nSáng 23/4, UBND huyện Phú Lộc ...   \n",
       "\n",
       "                                         summarization  \\\n",
       "0    Viện Khoa học Fraunhofer Đức đang phát triển l...   \n",
       "1    Tránh dùng sản phẩm sát trùng mạnh. Tránh tran...   \n",
       "2    Gần đây, Bộ Giao thông vận tải (GTVT) đã đưa r...   \n",
       "3    Frederik là một con ngựa Frieasian đến từ Hà L...   \n",
       "4    Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...   \n",
       "..                                                 ...   \n",
       "195  Đại hội Đảng bộ VCCI lần thứ VI nhiệm kỳ 2010-...   \n",
       "196  Nhạc sĩ Phạm Toàn Thắng đã có bản hit có tổng ...   \n",
       "197  Lực lượng chức năng đang tiến hành điều tra vụ...   \n",
       "198  Tại Nam Ấn Độ, có nhiều điểm đến thân thiện gi...   \n",
       "199  UBND huyện Phú Lộc đã tổ chức Lễ đón nhận bằng...   \n",
       "\n",
       "                                   generate_google_mt5  \n",
       "0    Viện Khoa học Fraunhofer, Đức đang phát triển ...  \n",
       "1    Tóm tắt ngắn gọn nội dung sau để vệ sinh khuyê...  \n",
       "2    Bộ Giao thông vận tải (GTVT) đã đưa ra giải ph...  \n",
       "3    Ông Frederik là một người hâm mộ của vị vua tr...  \n",
       "4    Thứ trưởng Bộ GTVT Nguyễn Nhật và đại diện các...  \n",
       "..                                                 ...  \n",
       "195  Tại giai đoạn 2015-2020, Đảng bộ VCCI đã đề ra...  \n",
       "196  Tổng hơn 13 triệu lượt view trong năm qua, tro...  \n",
       "197  Tại hầm đường bộ Phước Tượng, xe ô-tô tải Air ...  \n",
       "198  Tìm về Kodaikanal ở Tamil Nadu. Nằm giữa những...  \n",
       "199  Cây đa Đá Bạc, tại thị trấn Phú Lộc là cây di ...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_vit5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T17:15:23.383429300Z",
     "start_time": "2024-02-04T17:15:23.349319400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_vit5 = pd.read_csv('test_vit5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "rouge_scores = rouge_metric.compute(references=test_vit5['summarization'].tolist(), predictions=test_vit5['generate_vit5'].tolist(), use_stemmer=True, rouge_types=['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.48238559725754643,\n",
       " 'rouge2': 0.2402462123862481,\n",
       " 'rougeL': 0.33840521000242113}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
