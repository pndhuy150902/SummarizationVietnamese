{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:02:58.953735100Z",
     "start_time": "2024-02-06T11:02:58.942583600Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:02:59.388697Z",
     "start_time": "2024-02-06T11:02:59.194825300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0b324ea9f0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import logging, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_int8_training, TaskType, PeftConfig, PeftModel\n",
    "tqdm.pandas()\n",
    "logging.set_verbosity_error()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T11:03:05.920834Z",
     "start_time": "2024-02-06T11:03:03.208345300Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/full_train_data_summarization.csv')\n",
    "validation_data = pd.read_csv('../dataset/full_validation_data_summarization.csv')\n",
    "test_data = pd.read_csv('../dataset/full_test_data_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:10.229473200Z",
     "start_time": "2024-02-04T10:39:10.207968Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = 'VietAI/vit5-base'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:22.690308600Z",
     "start_time": "2024-02-04T10:39:13.663736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e4a1f9a2a89450fa46befec9d4d25ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96adcf37b2034c1f9e2b4caaa15dff8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31f072bd4284606892a079db7aecb65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e75fdff0af747098abd9a1cc3de1693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:24.900285200Z",
     "start_time": "2024-02-04T10:39:24.878907600Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "  inputs = [doc for doc in examples[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=2048, truncation=True, padding=True)\n",
    "  labels = tokenizer(text_target=examples[\"summarization\"], max_length=1024, truncation=True, padding=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:27.084875200Z",
     "start_time": "2024-02-04T10:39:26.837162800Z"
    }
   },
   "outputs": [],
   "source": [
    "new_data = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(validation_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:36.910769Z",
     "start_time": "2024-02-04T10:39:29.635534900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ed1e4f2b4745c588da5ab4098cee45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/50413 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e725f03f26f44eb7b03ef5d142beb224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=8):   0%|          | 0/2200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_new_data = new_data.map(preprocess_function, batched=True, num_proc=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:40:18.257759300Z",
     "start_time": "2024-02-04T10:40:18.235574300Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels.tolist(), skip_special_tokens=True)\n",
    "  decoded_preds = tokenizer.batch_decode(preds.tolist(), skip_special_tokens=True)\n",
    "  bleu_metric = evaluate.load(\"bleu\")\n",
    "  references = [[reference_text] for reference_text in decoded_labels]\n",
    "  bleu_scores = bleu_metric.compute(references=references, predictions=decoded_preds)\n",
    "  bleu_score_1 = None\n",
    "  bleu_score_2 = None\n",
    "  bleu_score_3 = None\n",
    "  bleu_score_4 = None\n",
    "  bleu_score_avg = None\n",
    "  for k, v in bleu_scores.items():\n",
    "    if k == \"precisions\":\n",
    "      bleu_score_1 = v[0]\n",
    "      bleu_score_2 = v[1]        \n",
    "      bleu_score_3 = v[2]        \n",
    "      bleu_score_4 = v[3]\n",
    "      bleu_score_avg = (bleu_score_1 + bleu_score_2 + bleu_score_3 + bleu_score_4)/4\n",
    "      break\n",
    "  return {\n",
    "    'bleu@1': bleu_score_1,\n",
    "    'bleu@2': bleu_score_2,\n",
    "    'bleu@3': bleu_score_3,\n",
    "    'bleu@4': bleu_score_4,\n",
    "    'bleu@avg': bleu_score_avg\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "  preds, labels = eval_preds\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "  rouge_metric = evaluate.load(\"rouge\")\n",
    "  rouge_scores = rouge_metric.compute(references=decoded_labels, predictions=decoded_preds, use_stemmer=True, rouge_types=['rouge1', 'rouge2', 'rougeL'])\n",
    "  return {k: round(v, 4) for k, v in rouge_scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a07e9023399428899372ee0367022bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b53f7dd5c04856bc26a8b9ad4ab395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, load_in_8bit=True, device_map='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 14,155,776 || all params: 240,106,752 || trainable%: 5.8956176292784965\n"
     ]
    }
   ],
   "source": [
    "# Config lora for ViT5 Base Model\n",
    "lora_config = LoraConfig(\n",
    "  r=32, \n",
    "  lora_alpha=64,\n",
    "  target_modules=[\"q\", \"k\", \"v\", \"o\", \"wi\", \"wo\", \"lm_head\"],\n",
    "  lora_dropout=0.05,\n",
    "  bias=\"none\",\n",
    "  task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "model = prepare_model_for_int8_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:39:43.023531600Z",
     "start_time": "2024-02-04T10:39:43.006130900Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:03.374728300Z",
     "start_time": "2024-02-04T10:41:03.343520200Z"
    }
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name.replace('/', '_').replace('-', '_')}_model_summarization\",\n",
    "    learning_rate=1e-5,\n",
    "    warmup_ratio=0.05,\n",
    "    weight_decay=0.01,\n",
    "    auto_find_batch_size=True,\n",
    "    num_train_epochs=2,\n",
    "    predict_with_generate=True,\n",
    "    group_by_length=True,\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=2,\n",
    "    report_to='wandb',\n",
    "    run_name=f'{model_name}',\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='no'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T10:41:04.950004800Z",
     "start_time": "2024-02-04T10:41:03.375831900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_new_data[\"train\"],\n",
    "    eval_dataset=tokenized_new_data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/SummarizationVietnamese/model_baseline/wandb/run-20240219_030604-3m4i393l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/phamduchuy159/huggingface/runs/3m4i393l' target=\"_blank\">VietAI/vit5-base</a></strong> to <a href='https://wandb.ai/phamduchuy159/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/phamduchuy159/huggingface' target=\"_blank\">https://wandb.ai/phamduchuy159/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/phamduchuy159/huggingface/runs/3m4i393l' target=\"_blank\">https://wandb.ai/phamduchuy159/huggingface/runs/3m4i393l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.1161, 'learning_rate': 7.92393026941363e-06, 'epoch': 0.08}\n",
      "{'loss': 0.6413, 'learning_rate': 9.691806564770735e-06, 'epoch': 0.16}\n",
      "{'loss': 0.5437, 'learning_rate': 9.274200283972273e-06, 'epoch': 0.24}\n",
      "{'loss': 0.4925, 'learning_rate': 8.856594003173808e-06, 'epoch': 0.32}\n",
      "{'loss': 0.4707, 'learning_rate': 8.438987722375345e-06, 'epoch': 0.4}\n",
      "{'loss': 0.4649, 'learning_rate': 8.021381441576882e-06, 'epoch': 0.48}\n",
      "{'loss': 0.4571, 'learning_rate': 7.603775160778419e-06, 'epoch': 0.56}\n",
      "{'loss': 0.468, 'learning_rate': 7.1861688799799555e-06, 'epoch': 0.63}\n",
      "{'loss': 0.452, 'learning_rate': 6.7685625991814915e-06, 'epoch': 0.71}\n",
      "{'loss': 0.4456, 'learning_rate': 6.350956318383029e-06, 'epoch': 0.79}\n",
      "{'loss': 0.4406, 'learning_rate': 5.933350037584565e-06, 'epoch': 0.87}\n",
      "{'loss': 0.4377, 'learning_rate': 5.515743756786103e-06, 'epoch': 0.95}\n",
      "{'loss': 0.4416, 'learning_rate': 5.098137475987639e-06, 'epoch': 1.03}\n",
      "{'loss': 0.4445, 'learning_rate': 4.680531195189176e-06, 'epoch': 1.11}\n",
      "{'loss': 0.4456, 'learning_rate': 4.262924914390712e-06, 'epoch': 1.19}\n",
      "{'loss': 0.4338, 'learning_rate': 3.845318633592249e-06, 'epoch': 1.27}\n",
      "{'loss': 0.4284, 'learning_rate': 3.427712352793786e-06, 'epoch': 1.35}\n",
      "{'loss': 0.428, 'learning_rate': 3.010106071995323e-06, 'epoch': 1.43}\n",
      "{'loss': 0.432, 'learning_rate': 2.5924997911968597e-06, 'epoch': 1.51}\n",
      "{'loss': 0.4301, 'learning_rate': 2.1748935103983965e-06, 'epoch': 1.59}\n",
      "{'loss': 0.431, 'learning_rate': 1.7572872295999331e-06, 'epoch': 1.67}\n",
      "{'loss': 0.4318, 'learning_rate': 1.33968094880147e-06, 'epoch': 1.75}\n",
      "{'loss': 0.4337, 'learning_rate': 9.220746680030068e-07, 'epoch': 1.82}\n",
      "{'loss': 0.4269, 'learning_rate': 5.044683872045436e-07, 'epoch': 1.9}\n",
      "{'loss': 0.4218, 'learning_rate': 8.686210640608035e-08, 'epoch': 1.98}\n",
      "{'train_runtime': 19739.992, 'train_samples_per_second': 5.108, 'train_steps_per_second': 0.639, 'train_loss': 1.077005112750006, 'epoch': 2.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=12604, training_loss=1.077005112750006, metrics={'train_runtime': 19739.992, 'train_samples_per_second': 5.108, 'train_steps_per_second': 0.639, 'train_loss': 1.077005112750006, 'epoch': 2.0})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_model_id = '../model_baseline/google_mt5_base_model_summarization/checkpoint-18000'\n",
    "config = PeftConfig.from_pretrained(peft_model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(config.base_model_name_or_path, load_in_8bit=True, device_map={\"\":0})\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "model = PeftModel.from_pretrained(model, peft_model_id, device_map={\"\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(text):\n",
    "  encoding = tokenizer(text, return_tensors=\"pt\")\n",
    "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "  outputs = model.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    early_stopping=False,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2\n",
    "  )\n",
    "  for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    torch.cuda.empty_cache()\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [10:00<00:00,  3.00s/it]\n"
     ]
    }
   ],
   "source": [
    "test_data[f'generate_vit5'] = test_data['context'].progress_apply(lambda x: generate_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>summarization</th>\n",
       "      <th>generate_google_mt5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Để khắc phục các nhược điểm nói trên, Viện Kho...</td>\n",
       "      <td>Viện Khoa học Fraunhofer Đức đang phát triển l...</td>\n",
       "      <td>Viện Khoa học Fraunhofer, Đức đang phát triển ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Không nên dùng sản phẩm sát trùng mạnh như Bac...</td>\n",
       "      <td>Tránh dùng sản phẩm sát trùng mạnh. Tránh tran...</td>\n",
       "      <td>Tóm tắt ngắn gọn nội dung sau để vệ sinh khuyê...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kỳ 1: Đổi giờ học, giờ làm - đúng nhưng chưa đ...</td>\n",
       "      <td>Gần đây, Bộ Giao thông vận tải (GTVT) đã đưa r...</td>\n",
       "      <td>Bộ Giao thông vận tải (GTVT) đã đưa ra giải ph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Theo San Francisco Globe, chú hắc mã này có ng...</td>\n",
       "      <td>Frederik là một con ngựa Frieasian đến từ Hà L...</td>\n",
       "      <td>Ông Frederik là một người hâm mộ của vị vua tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...</td>\n",
       "      <td>Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...</td>\n",
       "      <td>Thứ trưởng Bộ GTVT Nguyễn Nhật và đại diện các...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Trong giai đoạn 2015 2020, Đảng bộ VCCI đã đề ...</td>\n",
       "      <td>Đại hội Đảng bộ VCCI lần thứ VI nhiệm kỳ 2010-...</td>\n",
       "      <td>Tại giai đoạn 2015-2020, Đảng bộ VCCI đã đề ra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Bản hit của nhạc sĩ Phạm Toàn Thắng đã có tổng...</td>\n",
       "      <td>Nhạc sĩ Phạm Toàn Thắng đã có bản hit có tổng ...</td>\n",
       "      <td>Tổng hơn 13 triệu lượt view trong năm qua, tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Các lực lượng chức năng đang tiến hành điều tr...</td>\n",
       "      <td>Lực lượng chức năng đang tiến hành điều tra vụ...</td>\n",
       "      <td>Tại hầm đường bộ Phước Tượng, xe ô-tô tải Air ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Kodaikanal, Tamil Nadu.\\nMột điểm đến thân thi...</td>\n",
       "      <td>Tại Nam Ấn Độ, có nhiều điểm đến thân thiện gi...</td>\n",
       "      <td>Tìm về Kodaikanal ở Tamil Nadu. Nằm giữa những...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Cây đa Đá Bạc.\\nSáng 23/4, UBND huyện Phú Lộc ...</td>\n",
       "      <td>UBND huyện Phú Lộc đã tổ chức Lễ đón nhận bằng...</td>\n",
       "      <td>Cây đa Đá Bạc, tại thị trấn Phú Lộc là cây di ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    Để khắc phục các nhược điểm nói trên, Viện Kho...   \n",
       "1    Không nên dùng sản phẩm sát trùng mạnh như Bac...   \n",
       "2    Kỳ 1: Đổi giờ học, giờ làm - đúng nhưng chưa đ...   \n",
       "3    Theo San Francisco Globe, chú hắc mã này có ng...   \n",
       "4    Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...   \n",
       "..                                                 ...   \n",
       "195  Trong giai đoạn 2015 2020, Đảng bộ VCCI đã đề ...   \n",
       "196  Bản hit của nhạc sĩ Phạm Toàn Thắng đã có tổng...   \n",
       "197  Các lực lượng chức năng đang tiến hành điều tr...   \n",
       "198  Kodaikanal, Tamil Nadu.\\nMột điểm đến thân thi...   \n",
       "199  Cây đa Đá Bạc.\\nSáng 23/4, UBND huyện Phú Lộc ...   \n",
       "\n",
       "                                         summarization  \\\n",
       "0    Viện Khoa học Fraunhofer Đức đang phát triển l...   \n",
       "1    Tránh dùng sản phẩm sát trùng mạnh. Tránh tran...   \n",
       "2    Gần đây, Bộ Giao thông vận tải (GTVT) đã đưa r...   \n",
       "3    Frederik là một con ngựa Frieasian đến từ Hà L...   \n",
       "4    Tham dự buổi làm việc có Thứ trưởng Bộ GTVT Ng...   \n",
       "..                                                 ...   \n",
       "195  Đại hội Đảng bộ VCCI lần thứ VI nhiệm kỳ 2010-...   \n",
       "196  Nhạc sĩ Phạm Toàn Thắng đã có bản hit có tổng ...   \n",
       "197  Lực lượng chức năng đang tiến hành điều tra vụ...   \n",
       "198  Tại Nam Ấn Độ, có nhiều điểm đến thân thiện gi...   \n",
       "199  UBND huyện Phú Lộc đã tổ chức Lễ đón nhận bằng...   \n",
       "\n",
       "                                   generate_google_mt5  \n",
       "0    Viện Khoa học Fraunhofer, Đức đang phát triển ...  \n",
       "1    Tóm tắt ngắn gọn nội dung sau để vệ sinh khuyê...  \n",
       "2    Bộ Giao thông vận tải (GTVT) đã đưa ra giải ph...  \n",
       "3    Ông Frederik là một người hâm mộ của vị vua tr...  \n",
       "4    Thứ trưởng Bộ GTVT Nguyễn Nhật và đại diện các...  \n",
       "..                                                 ...  \n",
       "195  Tại giai đoạn 2015-2020, Đảng bộ VCCI đã đề ra...  \n",
       "196  Tổng hơn 13 triệu lượt view trong năm qua, tro...  \n",
       "197  Tại hầm đường bộ Phước Tượng, xe ô-tô tải Air ...  \n",
       "198  Tìm về Kodaikanal ở Tamil Nadu. Nằm giữa những...  \n",
       "199  Cây đa Đá Bạc, tại thị trấn Phú Lộc là cây di ...  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('test_vit5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-04T17:15:23.383429300Z",
     "start_time": "2024-02-04T17:15:23.349319400Z"
    }
   },
   "outputs": [],
   "source": [
    "test_vit5 = pd.read_csv('test_vit5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "rouge_scores = rouge_metric.compute(references=test_vit5['summarization'].tolist(), predictions=test_vit5['generate_vit5'].tolist(), use_stemmer=True, rouge_types=['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
