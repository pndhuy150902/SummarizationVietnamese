{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import logging, AutoModelForSeq2SeqLM, AutoTokenizer, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "logging.set_verbosity_error()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gc.collect()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('../dataset/full_train_data_summarization.csv')\n",
    "validation_data = pd.read_csv('../dataset/full_validation_data_summarization.csv')\n",
    "test_data = pd.read_csv('../dataset/full_test_data_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[:6000]\n",
    "validation_data = validation_data[:200]\n",
    "test_data = test_data[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"Hãy tóm tắt ngắn gọn nội dung sau bằng tiếng Việt: \"\n",
    "def preprocess_function(examples):\n",
    "  inputs = [prefix + doc for doc in examples[\"context\"]]\n",
    "  model_inputs = tokenizer(inputs, max_length=4096, truncation=True)\n",
    "  labels = tokenizer(text_target=examples[\"summarization\"], max_length=1024, truncation=True)\n",
    "  model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "  return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = DatasetDict({\n",
    "    \"train\": Dataset.from_dict(train_data),\n",
    "    \"validation\": Dataset.from_dict(validation_data)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_new_data = new_data.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "  predictions, labels = eval_pred\n",
    "  decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "  labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "  decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "  bleu_scores_ngram_1 = []\n",
    "  bleu_scores_ngram_2 = []\n",
    "  bleu_scores_ngram_3 = []\n",
    "  bleu_scores_ngram_4 = []\n",
    "  bleu_scores_ngram_avg = []\n",
    "  for reference_text, generated_text in zip(decoded_labels, decoded_preds):\n",
    "    bleu_score_ngram_1 = sentence_bleu([reference_text], generated_text, weights=(1, 0, 0, 0))\n",
    "    bleu_score_ngram_2 = sentence_bleu([reference_text], generated_text, weights=(0, 1, 0, 0))\n",
    "    bleu_score_ngram_3 = sentence_bleu([reference_text], generated_text, weights=(0, 0, 1, 0))\n",
    "    bleu_score_ngram_4 = sentence_bleu([reference_text], generated_text, weights=(0, 0, 0, 1))\n",
    "    bleu_score_ngram_avg = sentence_bleu([reference_text], generated_text, weights=(0.25, 0.25, 0.25, 0.25))\n",
    "    bleu_scores_ngram_1.append(bleu_score_ngram_1)\n",
    "    bleu_scores_ngram_2.append(bleu_score_ngram_2)\n",
    "    bleu_scores_ngram_3.append(bleu_score_ngram_3)\n",
    "    bleu_scores_ngram_4.append(bleu_score_ngram_4)\n",
    "    bleu_scores_ngram_avg.append(bleu_score_ngram_avg)\n",
    "\n",
    "  return {\n",
    "    'bleu@1': sum(bleu_scores_ngram_1) / len(bleu_scores_ngram_1),\n",
    "    'bleu@2': sum(bleu_scores_ngram_2) / len(bleu_scores_ngram_2),\n",
    "    'bleu@3': sum(bleu_scores_ngram_3) / len(bleu_scores_ngram_3),\n",
    "    'bleu@4': sum(bleu_scores_ngram_4) / len(bleu_scores_ngram_4),\n",
    "    'bleu@avg': sum(bleu_scores_ngram_avg) / len(bleu_scores_ngram_avg)\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"{model_name.replace('/', '_')}_model_summarization\",\n",
    "    learning_rate=1e-5,\n",
    "    auto_find_batch_size=True,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    "    save_total_limit=1,\n",
    "    save_strategy='epoch',\n",
    "    evaluation_strategy='epoch'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_new_data[\"train\"],\n",
    "    eval_dataset=tokenized_new_data[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Model Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = ''\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)  \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "model.to(device)\n",
    "if torch.cuda.device_count() >= 2:\n",
    "  model = torch.nn.DataParallel(model)\n",
    "\n",
    "def generate_text(text):\n",
    "  prefix = 'Hãy tóm tắt ngắn gọn nội dung sau bằng tiếng Việt: '\n",
    "  encoding = tokenizer(prefix+text, return_tensors=\"pt\")\n",
    "  input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "  outputs = model.module.generate(\n",
    "    input_ids=input_ids, attention_mask=attention_masks,\n",
    "    early_stopping=False,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8\n",
    "  )\n",
    "  for output in outputs:\n",
    "    line = tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[f'generate_{model_name.replace('/', '_')}'] = test_data['context'].apply(lambda x: generate_text(x))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
