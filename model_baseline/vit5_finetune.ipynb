{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-27T16:20:23.668626Z","iopub.status.busy":"2024-06-27T16:20:23.667970Z","iopub.status.idle":"2024-06-27T16:20:42.712538Z","shell.execute_reply":"2024-06-27T16:20:42.711599Z","shell.execute_reply.started":"2024-06-27T16:20:23.668595Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-06-27 16:20:32.399961: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-06-27 16:20:32.400084: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-06-27 16:20:32.530691: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"]}],"source":["import os\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","import pandas as pd\n","from datasets import Dataset\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainer, TrainingArguments, Seq2SeqTrainingArguments\n","from tqdm.notebook import tqdm\n","from torch.utils.data import DataLoader"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:20:42.714580Z","iopub.status.busy":"2024-06-27T16:20:42.714059Z","iopub.status.idle":"2024-06-27T16:20:48.124014Z","shell.execute_reply":"2024-06-27T16:20:48.122990Z","shell.execute_reply.started":"2024-06-27T16:20:42.714552Z"},"trusted":true},"outputs":[],"source":["train_dataset = pd.read_csv(\"../dataset/train_dataset_clean.csv\")\n","test_dataset = pd.read_csv(\"../dataset/test_dataset_clean.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:20:48.125614Z","iopub.status.busy":"2024-06-27T16:20:48.125328Z","iopub.status.idle":"2024-06-27T16:20:55.117719Z","shell.execute_reply":"2024-06-27T16:20:55.116869Z","shell.execute_reply.started":"2024-06-27T16:20:48.125590Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bce56cb5b0324c329da335c322592fcc","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a7d0d53c8b3e41c18d4a38e84743d05c","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/820k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a4c6dcced9bd48aaa6fc20e0ff365bb4","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.40M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"14de281e1df84bb1abea54106e7fe5a0","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.12k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6bd3467e51254f9b83d9f4c0305fb8fd","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d0c30fc634ec4197bf777c411f4913c4","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/904M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer = AutoTokenizer.from_pretrained(\"VietAI/vit5-base\")  \n","model = AutoModelForSeq2SeqLM.from_pretrained(\"VietAI/vit5-base\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:20:55.120254Z","iopub.status.busy":"2024-06-27T16:20:55.119967Z","iopub.status.idle":"2024-06-27T16:20:55.125501Z","shell.execute_reply":"2024-06-27T16:20:55.124618Z","shell.execute_reply.started":"2024-06-27T16:20:55.120230Z"},"trusted":true},"outputs":[],"source":["def preprocess_function(examples):\n","    model_inputs = tokenizer(\n","        examples[\"inputs\"], max_length=1024, truncation=True, padding=True\n","    )\n","    \n","    with tokenizer.as_target_tokenizer():\n","        labels = tokenizer(\n","            examples[\"labels\"], max_length=256, truncation=True, padding=True\n","        )\n","    model_inputs['labels'] = labels['input_ids']\n","    model_inputs['input_ids'] = model_inputs['input_ids']\n","    return model_inputs"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:20:55.126795Z","iopub.status.busy":"2024-06-27T16:20:55.126505Z","iopub.status.idle":"2024-06-27T16:22:00.659329Z","shell.execute_reply":"2024-06-27T16:22:00.658516Z","shell.execute_reply.started":"2024-06-27T16:20:55.126767Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8cfe776dae74434e88d21cb48ff6cb9c","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/59949 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dict_obj = {'inputs': [\"summarization: \" + t for t in train_dataset[\"context\"].tolist()], 'labels': train_dataset[\"summarization\"].tolist()}\n","dataset = Dataset.from_dict(dict_obj)\n","tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:22:00.660701Z","iopub.status.busy":"2024-06-27T16:22:00.660405Z","iopub.status.idle":"2024-06-27T16:22:00.687574Z","shell.execute_reply":"2024-06-27T16:22:00.686865Z","shell.execute_reply.started":"2024-06-27T16:22:00.660670Z"},"trusted":true},"outputs":[],"source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n","training_args = Seq2SeqTrainingArguments(\"tmp/\",\n","                                        do_train=True,\n","                                        do_eval=False,\n","                                        num_train_epochs=30,\n","                                        learning_rate=1e-5,\n","                                        warmup_ratio=0.05,\n","                                        weight_decay=0.01,\n","                                        per_device_train_batch_size=8,\n","                                        per_device_eval_batch_size=8,\n","                                        logging_dir='./log',\n","                                        group_by_length=True,\n","                                        save_strategy=\"epoch\",\n","                                        save_total_limit=3,\n","                                        report_to=\"none\",\n","                                        #eval_steps=1,\n","                                        #evaluation_strategy=\"steps\",\n","                                        # evaluation_strategy=\"no\",\n","                                        fp16=True,\n","                                        )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-27T16:22:00.689129Z","iopub.status.busy":"2024-06-27T16:22:00.688697Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='234' max='449640' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [   234/449640 03:26 < 110:51:47, 1.13 it/s, Epoch 0.02/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","trainer.train()"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T08:44:01.448137Z","iopub.status.busy":"2024-06-25T08:44:01.447849Z","iopub.status.idle":"2024-06-25T12:34:12.068719Z","shell.execute_reply":"2024-06-25T12:34:12.067866Z","shell.execute_reply.started":"2024-06-25T08:44:01.448112Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='15000' max='15000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [15000/15000 3:50:05, Epoch 30/30]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>7.338700</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.444300</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.373200</td>\n","    </tr>\n","    <tr>\n","      <td>2000</td>\n","      <td>0.332800</td>\n","    </tr>\n","    <tr>\n","      <td>2500</td>\n","      <td>0.298800</td>\n","    </tr>\n","    <tr>\n","      <td>3000</td>\n","      <td>0.273300</td>\n","    </tr>\n","    <tr>\n","      <td>3500</td>\n","      <td>0.252000</td>\n","    </tr>\n","    <tr>\n","      <td>4000</td>\n","      <td>0.233200</td>\n","    </tr>\n","    <tr>\n","      <td>4500</td>\n","      <td>0.215700</td>\n","    </tr>\n","    <tr>\n","      <td>5000</td>\n","      <td>0.200100</td>\n","    </tr>\n","    <tr>\n","      <td>5500</td>\n","      <td>0.186400</td>\n","    </tr>\n","    <tr>\n","      <td>6000</td>\n","      <td>0.173300</td>\n","    </tr>\n","    <tr>\n","      <td>6500</td>\n","      <td>0.162700</td>\n","    </tr>\n","    <tr>\n","      <td>7000</td>\n","      <td>0.153400</td>\n","    </tr>\n","    <tr>\n","      <td>7500</td>\n","      <td>0.144100</td>\n","    </tr>\n","    <tr>\n","      <td>8000</td>\n","      <td>0.136200</td>\n","    </tr>\n","    <tr>\n","      <td>8500</td>\n","      <td>0.128300</td>\n","    </tr>\n","    <tr>\n","      <td>9000</td>\n","      <td>0.121500</td>\n","    </tr>\n","    <tr>\n","      <td>9500</td>\n","      <td>0.116000</td>\n","    </tr>\n","    <tr>\n","      <td>10000</td>\n","      <td>0.111500</td>\n","    </tr>\n","    <tr>\n","      <td>10500</td>\n","      <td>0.105700</td>\n","    </tr>\n","    <tr>\n","      <td>11000</td>\n","      <td>0.102300</td>\n","    </tr>\n","    <tr>\n","      <td>11500</td>\n","      <td>0.097500</td>\n","    </tr>\n","    <tr>\n","      <td>12000</td>\n","      <td>0.095900</td>\n","    </tr>\n","    <tr>\n","      <td>12500</td>\n","      <td>0.091800</td>\n","    </tr>\n","    <tr>\n","      <td>13000</td>\n","      <td>0.090200</td>\n","    </tr>\n","    <tr>\n","      <td>13500</td>\n","      <td>0.087100</td>\n","    </tr>\n","    <tr>\n","      <td>14000</td>\n","      <td>0.085600</td>\n","    </tr>\n","    <tr>\n","      <td>14500</td>\n","      <td>0.084900</td>\n","    </tr>\n","    <tr>\n","      <td>15000</td>\n","      <td>0.084100</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["TrainOutput(global_step=15000, training_loss=0.41068628362019854, metrics={'train_runtime': 13807.0243, 'train_samples_per_second': 4.346, 'train_steps_per_second': 1.086, 'total_flos': 7.093293272967168e+16, 'train_loss': 0.41068628362019854, 'epoch': 30.0})"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets,\n","    data_collator=data_collator,\n",")\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["### 0831a3a3616890850056cf141ac075468be7898c"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:35:05.516617Z","iopub.status.busy":"2024-06-25T12:35:05.515677Z","iopub.status.idle":"2024-06-25T12:35:18.153630Z","shell.execute_reply":"2024-06-25T12:35:18.152378Z","shell.execute_reply.started":"2024-06-25T12:35:05.516582Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n","To disable this warning, you can either:\n","\t- Avoid using `tokenizers` before the fork if possible\n","\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"]},{"name":"stdout","output_type":"stream","text":["Collecting rouge-score\n","  Using cached rouge_score-0.1.2-py3-none-any.whl\n","Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n","Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.26.4)\n","Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n","Installing collected packages: rouge-score\n","Successfully installed rouge-score-0.1.2\n"]}],"source":["!pip install rouge-score"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:35:18.156434Z","iopub.status.busy":"2024-06-25T12:35:18.156040Z","iopub.status.idle":"2024-06-25T12:35:18.516620Z","shell.execute_reply":"2024-06-25T12:35:18.515775Z","shell.execute_reply.started":"2024-06-25T12:35:18.156397Z"},"trusted":true},"outputs":[],"source":["from datasets import load_metric\n","metric = load_metric(\"rouge\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:35:23.044778Z","iopub.status.busy":"2024-06-25T12:35:23.043962Z","iopub.status.idle":"2024-06-25T12:35:23.575787Z","shell.execute_reply":"2024-06-25T12:35:23.574898Z","shell.execute_reply.started":"2024-06-25T12:35:23.044724Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8bc3b1f486194974abee349ec219e3e6","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/400 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["dict_obj = {'inputs': [\"summarization: \" + t for t in test_dataset[\"context\"].tolist()], 'labels': test_dataset[\"summarization\"].tolist()}\n","dataset = Dataset.from_dict(dict_obj)\n","test_tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=['inputs'], num_proc=10)\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-25T12:34:57.061539Z","iopub.status.idle":"2024-06-25T12:34:57.062044Z","shell.execute_reply":"2024-06-25T12:34:57.061805Z","shell.execute_reply.started":"2024-06-25T12:34:57.061714Z"},"trusted":true},"outputs":[],"source":["import gc\n","del model\n","gc.collect()"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:49:39.718287Z","iopub.status.busy":"2024-06-25T12:49:39.717467Z","iopub.status.idle":"2024-06-25T12:49:40.817037Z","shell.execute_reply":"2024-06-25T12:49:40.816058Z","shell.execute_reply.started":"2024-06-25T12:49:39.718254Z"},"trusted":true},"outputs":[{"data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(36096, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(36096, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=36096, bias=False)\n",")"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["model = AutoModelForSeq2SeqLM.from_pretrained(\"/kaggle/working/tmp/checkpoint-14000\")\n","model.to('cuda')"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:49:40.819130Z","iopub.status.busy":"2024-06-25T12:49:40.818847Z","iopub.status.idle":"2024-06-25T12:51:35.368783Z","shell.execute_reply":"2024-06-25T12:51:35.367700Z","shell.execute_reply.started":"2024-06-25T12:49:40.819106Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50c1ebe5032444579c11bce62f0e2801","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/13 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"text/plain":["{'rouge1': AggregateScore(low=Score(precision=0.6026097897215744, recall=0.7000448956590815, fmeasure=0.6240095408412721), mid=Score(precision=0.6195843943006647, recall=0.7135890758766179, fmeasure=0.6358940671340347), high=Score(precision=0.6374614345252361, recall=0.7289447499813153, fmeasure=0.6473509259712777)),\n"," 'rouge2': AggregateScore(low=Score(precision=0.3369934095843084, recall=0.381634127297341, fmeasure=0.34386999253849), mid=Score(precision=0.3547862219348622, recall=0.3982899600920672, fmeasure=0.35915689282987245), high=Score(precision=0.37396698728713784, recall=0.4147375154055437, fmeasure=0.37560013277705223)),\n"," 'rougeL': AggregateScore(low=Score(precision=0.39807968024023704, recall=0.45777483980716455, fmeasure=0.4093900471067679), mid=Score(precision=0.4136225237741678, recall=0.4711564814221314, fmeasure=0.421852808706527), high=Score(precision=0.4299618591956141, recall=0.48512056778463236, fmeasure=0.43423404455558917)),\n"," 'rougeLsum': AggregateScore(low=Score(precision=0.3996979132813376, recall=0.45783487850958454, fmeasure=0.4107569455675927), mid=Score(precision=0.41339458119371153, recall=0.471394713279682, fmeasure=0.4219892402166645), high=Score(precision=0.43002519077599183, recall=0.48476616902335196, fmeasure=0.4340110225753673))}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["import torch \n","import numpy as np\n","metrics = load_metric('rouge')\n","\n","max_target_length = 256\n","dataloader = torch.utils.data.DataLoader(test_tokenized_datasets, collate_fn=data_collator, batch_size=32)\n","\n","predictions = []\n","references = []\n","for i, batch in enumerate(tqdm(dataloader)):\n","  outputs = model.generate(\n","      input_ids=batch['input_ids'].to('cuda'),\n","      max_length=max_target_length,\n","      attention_mask=batch['attention_mask'].to('cuda'),\n","  )\n","  with tokenizer.as_target_tokenizer():\n","    outputs = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in outputs]\n","\n","    labels = np.where(batch['labels'] != -100,  batch['labels'], tokenizer.pad_token_id)\n","    actuals = [tokenizer.decode(out, clean_up_tokenization_spaces=False, skip_special_tokens=True) for out in labels]\n","  predictions.extend(outputs)\n","  references.extend(actuals)\n","  metrics.add_batch(predictions=outputs, references=actuals)\n","\n","\n","metrics.compute()"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-06-25T12:51:35.371106Z","iopub.status.busy":"2024-06-25T12:51:35.370665Z","iopub.status.idle":"2024-06-25T12:51:43.345512Z","shell.execute_reply":"2024-06-25T12:51:43.344565Z","shell.execute_reply.started":"2024-06-25T12:51:35.371069Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[{'rouge1': 0.6358940671340347},\n"," {'rouge2': 0.35915689282987245},\n"," {'rougeL': 0.421852808706527},\n"," {'rougeLsum': 0.4219892402166645}]"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["[{k: v.mid.fmeasure} for k,v in metrics.compute(predictions=predictions, references=references).items()]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5274634,"sourceId":8776016,"sourceType":"datasetVersion"},{"datasetId":5294850,"sourceId":8804132,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
