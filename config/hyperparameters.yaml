processed_data:
  train_data: "../dataset/full_train_data_summarization.csv"
  valid_data: "../dataset/full_validation_data_summarization.csv"
  test_data: "../dataset/full_test_data_summarization.csv"

model_name: "mistralai/Mixtral-8x7B-Instruct-v0.1"

args_training:
  num_train_epochs: 20
  learning_rate: 1e-5
  save_total_limit: 2
  logging_steps: 1
  dir_checkpoint: "./model_checkpoint"
  save_strategy: "epoch"
  optimizer: "paged_adamw_8bit"

deepspeed:
  stage_2: "deepspeed_stage_2"

length:
  text: 20480
  summary: 2048
