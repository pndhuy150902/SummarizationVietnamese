processed_data:
  train_data: "../dataset/full_train_data_summarization.csv"
  valid_data: "../dataset/full_validation_data_summarization.csv"
  test_data: "../dataset/full_test_data_summarization.csv"

model_name: "mistralai/Mixtral-8x7B-Instruct-v0.1"
model_name_test: "mistralai/Mistral-7B-Instruct-v0.2"

args_training:
  train_batch_size: 2
  eval_batch_size: 2
  num_train_epochs: 6
  learning_rate: 1e-5
  save_total_limit: 1
  logging_steps: 1
  dir_checkpoint: "./model_checkpoint"
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  optimizer: "paged_adamw_8bit"

deepspeed:
  stage_2: "../config/deepspeed_stage_2.json"

length:
  text: 12288
  summary: 2048
