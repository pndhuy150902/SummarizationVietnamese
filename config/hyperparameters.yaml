processed_data:
  train_data: "../dataset/full_train_data_summarization.csv"
  valid_data: "../dataset/full_validation_data_summarization.csv"
  test_data: "../dataset/full_test_data_summarization.csv"

model_mixtral: "mistralai/Mixtral-8x7B-Instruct-v0.1"
model_mistral: "mistralai/Mistral-7B-Instruct-v0.2"

args_training:
  train_batch_size: 16
  eval_batch_size: 16
  num_train_epochs: 2
  learning_rate: 2e-5
  save_total_limit: 2
  logging_steps: 25
  dir_checkpoint: "./model_checkpoint"
  save_strategy: "epoch"
  evaluation_strategy: "epoch"
  optimizer: "paged_adamw_8bit"

deepspeed:
  stage_2: "../config/deepspeed_stage_2.json"
  stage_2_offload: "../config/deepspeed_stage_2_offload.json"
  stage_3: "../config/deepspeed_stage_3.json"
  stage_3_offload: "../config/deepspeed_stage_3_offload.json"

length:
  text: 4096
  summary: 1024
