{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb13e299",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import gc\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d791c100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bin d:\\PythonVenv\\lib\\site-packages\\bitsandbytes\\libbitsandbytes_cuda118.dll\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29fd3cd6af0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import evaluate\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from peft import PeftModel, PeftConfig\n",
    "from transformers import BitsAndBytesConfig, AutoTokenizer, AutoModelForCausalLM, DataCollatorForLanguageModeling\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "tqdm.pandas()\n",
    "gc.collect()\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d38551",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_test = pd.read_csv('../dataset/full_test_data_summarization.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ffe0d7e5ede1fea",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = './model_checkpoint/new-checkpoint/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921f6a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PeftConfig.from_pretrained(checkpoint)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    config.base_model_name_or_path,\n",
    "    device_map={\"\":0},\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    attn_implementation=\"flash_attention_2\",\n",
    "    quantization_config=BitsAndBytesConfig(    \n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type='nf4',\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16\n",
    "    ),\n",
    "    token=\"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\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenizer.padding_side = \"left\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17876766",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModel.from_pretrained(base_model, checkpoint, device_map={\"\":0})\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de35050220e391d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def create_prompt(sample):\n",
    "    template = \"\"\"<s>[INST] Bạn là một trợ lý AI. Bạn sẽ được giao một nhiệm vụ. Hãy tóm lược ngắn gọn nội dung sau bằng tiếng Việt:\n",
    "{} [/INST]\"\"\"\n",
    "    prompt = template.format(sample)\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fdd22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"HoREA cho rằng TP.HCM là nơi có khối lượng công việc hành chính, dịch vụ công, trong đó có công tác cấp giấy chứng nhận quyền sử dụng đất (sổ đỏ) rất lớn, gấp nhiều lần khối lượng ở các tỉnh.Lâu nay, khối lượng công việc cấp sổ đỏ dồn về Sở Tài nguyên - Môi trường, dẫn đến quá tải.Gần đây, khi Nghị định 01/2017/NĐ-CP có hiệu lực ngày 3.3.2017, trong đó có quy định UBND cấp tỉnh căn cứ điều kiện cụ thể tại địa phương để quy định việc cho phép Sở Tài nguyên - Môi trường được ủy quyền cho Văn phòng đăng ký đất đai cấp giấy chứng nhận quyền sử dụng đất.Tuy nhiên, HoREA nói rằng quy định này trên thực tế sẽ chỉ chuyển điểm ùn ứ hồ sơ từ Sở Tài nguyên-Môi trường sang Văn phòng đăng ký đất đai thành phố, chưa đẩy nhanh tiến độ cho người dân. Ngoài ra, theo Nghị định 01/2017/NĐ-CP, Sở Tài nguyên-Môi trường không được phép ủy quyền cấp sổ đỏ cho chi nhánh Văn phòng đăng ký đất đai tại các quận huyện. Do đó, HoREA kiến nghị Chính phủ xem xét sửa đổi, bổ sung Nghị định 01, hoặc cho thí điểm thực hiện việc giao quyền cho chi nhánh Văn phòng đăng ký đất đai tại các quận huyện của TP.HCM, TP.Hà Nội được phép cấp sổ đỏ.Hiệp hội nhận thấy một chiếc áo hành chính không thể mặc vừa cho tất cả 63 tỉnh, thành phố trực thuộc Trung ương. TP.HCM, Hà Nội cần có cơ chế đặc thù riêng để giải quyết các thủ tục hành chính phù hợp với điều kiện của chính quyền đô thị. Do vậy, việc giao quyền cho chi nhánh Văn phòng đăng ký đất đai tại các quận, huyện tại TP.HCM, Hà Nội được cấp giấy chứng nhận quyền sử dụng đất là hết sức cần thiết và cấp bách, giải quyết nhanh và kịp thời nhu cầu của người dân, ông Lê Hoàng Châu Chủ tịch HoREA nhận định.Đáng chú ý,trong khi chờ đợi sửa đổi, Hiệp hội đề xuất UBND TP.HCM ban hành sớm quy chế phối hợp giải quyết thủ tục đất theo Nghị định 01, cho phép Sở Tài nguyên - Môi trường được ủy quyền cho Văn phòng đăng ký đất đai cấp sổ đỏ, đồng thời công bố bộ thủ tục hành chính về đất đai để áp dụng thống nhất trên địa bàn thành phố. Phan Diệu.\"\"\"\n",
    "inputs = tokenizer(create_prompt(text), add_special_tokens=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "outputs = model.generate(\n",
    "  **inputs,\n",
    "  early_stopping=False,\n",
    "  max_new_tokens=1024,\n",
    "  temperature=0.7,\n",
    "  top_p=0.8,\n",
    "  top_k=50,\n",
    "  repetition_penalty=1.2,\n",
    "  pad_token_id=tokenizer.unk_token_id\n",
    ")\n",
    "tokenizer.decode(outputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=False).split('[/INST]')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8869c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "predictions = []\n",
    "def generate_text():\n",
    "  for batch_1, batch_2 in tqdm(zip(torch.utils.data.DataLoader(full_data_test['context'], batch_size=32, shuffle=False), torch.utils.data.DataLoader(full_data_test['summarization'], batch_size=32, shuffle=False), strict=True), total=int(round(len(full_data_test)/32, 0))):\n",
    "    prompts = [create_prompt(context) for context in batch_1]\n",
    "    inputs = tokenizer(prompts, add_special_tokens=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "      **inputs,\n",
    "      early_stopping=False,\n",
    "      max_new_tokens=1024,\n",
    "      temperature=0.7,\n",
    "      top_p=0.8,\n",
    "      top_k=50,\n",
    "      repetition_penalty=1.2,\n",
    "      pad_token_id=tokenizer.unk_token_id\n",
    "    )\n",
    "    references.extend(batch_2)\n",
    "    predictions.extend([tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=False).split('[/INST]')[1].strip() for output in outputs])\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988564f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "predictions = []\n",
    "def generate_text():\n",
    "  for batch_1, batch_2 in tqdm(zip(torch.utils.data.DataLoader(full_data_test['context'], batch_size=32, shuffle=False), torch.utils.data.DataLoader(full_data_test['summarization'], batch_size=32, shuffle=False), strict=True), total=int(round(len(full_data_test)/32, 0))):\n",
    "    prompts = [create_prompt(context) for context in batch_1]\n",
    "    inputs = tokenizer(prompts, add_special_tokens=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(\n",
    "      **inputs,\n",
    "      early_stopping=False,\n",
    "      max_new_tokens=1024,\n",
    "      temperature=0.7,\n",
    "      top_k=10,\n",
    "      penalty_alpha=0.8,\n",
    "      repetition_penalty=1.2,\n",
    "      pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    references.extend(batch_2)\n",
    "    predictions.extend([tokenizer.decode(output, skip_special_tokens=True, clean_up_tokenization_spaces=False).split('[/INST]')[1].strip() for output in outputs])\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ce43e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_test['summarization_predictions'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd11efeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "rouge_scores = rouge_metric.compute(references=references, predictions=predictions, use_stemmer=True, rouge_types=['rouge1', 'rouge2', 'rougeL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aaa17e8bd83fd88b",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge1': 0.6073709993163005,\n",
       " 'rouge2': 0.3535813077835422,\n",
       " 'rougeL': 0.4224855441941776}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd2930552f0f3689",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "full_data_test.to_csv('test_mistral_lora_v2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aee9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
